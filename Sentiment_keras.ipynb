{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "np.random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17154048/17464789 [============================>.] - ETA: 0s(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data (it's preloaded in Keras)\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=5000,skip_top=50)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 2, 173, 2, 256, 2, 2, 100, 2, 838, 112, 50, 670, 2, 2, 2, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 2, 2, 172, 4536, 1111, 2, 546, 2, 2, 447, 2, 192, 50, 2, 2, 147, 2025, 2, 2, 2, 2, 1920, 4613, 469, 2, 2, 71, 87, 2, 2, 2, 530, 2, 76, 2, 2, 1247, 2, 2, 2, 515, 2, 2, 2, 626, 2, 2, 2, 62, 386, 2, 2, 316, 2, 106, 2, 2, 2223, 2, 2, 480, 66, 3785, 2, 2, 130, 2, 2, 2, 619, 2, 2, 124, 51, 2, 135, 2, 2, 1415, 2, 2, 2, 2, 215, 2, 77, 52, 2, 2, 407, 2, 82, 2, 2, 2, 107, 117, 2, 2, 256, 2, 2, 2, 3766, 2, 723, 2, 71, 2, 530, 476, 2, 400, 317, 2, 2, 2, 2, 1029, 2, 104, 88, 2, 381, 2, 297, 98, 2, 2071, 56, 2, 141, 2, 194, 2, 2, 2, 226, 2, 2, 134, 476, 2, 480, 2, 144, 2, 2, 2, 51, 2, 2, 224, 92, 2, 104, 2, 226, 65, 2, 2, 1334, 88, 2, 2, 283, 2, 2, 4472, 113, 103, 2, 2, 2, 2, 2, 178, 2]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding the training data into vector mode, each of length 1000\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding the testing data\n",
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting the length of reviews to 1000 words. Truncating reviews longer than this\n",
    "max_words = 1000\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_words)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 513,538\n",
      "Trainable params: 513,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model architecture with one layer of length 100\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='sigmoid', input_dim=1000))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(64, activation='sigmoid'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Compiling the model using categorical_crossentropy loss, and rmsprop optimizer.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "8s - loss: 0.4332 - acc: 0.7948 - val_loss: 0.3290 - val_acc: 0.8620\n",
      "Epoch 2/50\n",
      "7s - loss: 0.3419 - acc: 0.8551 - val_loss: 0.3238 - val_acc: 0.8592\n",
      "Epoch 3/50\n",
      "7s - loss: 0.3262 - acc: 0.8614 - val_loss: 0.3397 - val_acc: 0.8518\n",
      "Epoch 4/50\n",
      "7s - loss: 0.3200 - acc: 0.8632 - val_loss: 0.3261 - val_acc: 0.8568\n",
      "Epoch 5/50\n",
      "7s - loss: 0.3144 - acc: 0.8681 - val_loss: 0.3237 - val_acc: 0.8608\n",
      "Epoch 6/50\n",
      "7s - loss: 0.3104 - acc: 0.8698 - val_loss: 0.3278 - val_acc: 0.8620\n",
      "Epoch 7/50\n",
      "7s - loss: 0.3072 - acc: 0.8711 - val_loss: 0.3246 - val_acc: 0.8642\n",
      "Epoch 8/50\n",
      "7s - loss: 0.3059 - acc: 0.8724 - val_loss: 0.3260 - val_acc: 0.8636\n",
      "Epoch 9/50\n",
      "7s - loss: 0.3033 - acc: 0.8728 - val_loss: 0.3344 - val_acc: 0.8578\n",
      "Epoch 10/50\n",
      "7s - loss: 0.3016 - acc: 0.8746 - val_loss: 0.3280 - val_acc: 0.8634\n",
      "Epoch 11/50\n",
      "7s - loss: 0.2998 - acc: 0.8728 - val_loss: 0.3297 - val_acc: 0.8632\n",
      "Epoch 12/50\n",
      "7s - loss: 0.2977 - acc: 0.8747 - val_loss: 0.3307 - val_acc: 0.8616\n",
      "Epoch 13/50\n",
      "7s - loss: 0.2969 - acc: 0.8771 - val_loss: 0.3373 - val_acc: 0.8582\n",
      "Epoch 14/50\n",
      "7s - loss: 0.2975 - acc: 0.8780 - val_loss: 0.3283 - val_acc: 0.8660\n",
      "Epoch 15/50\n",
      "7s - loss: 0.2962 - acc: 0.8776 - val_loss: 0.3315 - val_acc: 0.8614\n",
      "Epoch 16/50\n",
      "7s - loss: 0.2949 - acc: 0.8773 - val_loss: 0.3292 - val_acc: 0.8608\n",
      "Epoch 17/50\n",
      "7s - loss: 0.2951 - acc: 0.8788 - val_loss: 0.3316 - val_acc: 0.8642\n",
      "Epoch 18/50\n",
      "7s - loss: 0.2936 - acc: 0.8788 - val_loss: 0.3368 - val_acc: 0.8588\n",
      "Epoch 19/50\n",
      "7s - loss: 0.2936 - acc: 0.8808 - val_loss: 0.3290 - val_acc: 0.8628\n",
      "Epoch 20/50\n",
      "9s - loss: 0.2936 - acc: 0.8815 - val_loss: 0.3282 - val_acc: 0.8638\n",
      "Epoch 21/50\n",
      "10s - loss: 0.2924 - acc: 0.8808 - val_loss: 0.3346 - val_acc: 0.8602\n",
      "Epoch 22/50\n",
      "7s - loss: 0.2906 - acc: 0.8813 - val_loss: 0.3341 - val_acc: 0.8606\n",
      "Epoch 23/50\n",
      "7s - loss: 0.2899 - acc: 0.8825 - val_loss: 0.3337 - val_acc: 0.8638\n",
      "Epoch 24/50\n",
      "9s - loss: 0.2895 - acc: 0.8818 - val_loss: 0.3401 - val_acc: 0.8596\n",
      "Epoch 25/50\n",
      "8s - loss: 0.2891 - acc: 0.8810 - val_loss: 0.3377 - val_acc: 0.8624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f3a70a2a58>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running and evaluating the model\n",
    "\n",
    "# Reducing learning rate\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
    "#                              patience=5, min_lr=0.001)\n",
    "\n",
    "# Early stopping\n",
    "es = EarlyStopping(monitor='val_acc',\n",
    "                              min_delta=1e-3,\n",
    "                              patience=10,\n",
    "                              verbose=0, mode='auto')\n",
    "model.fit(x_train, y_train,\n",
    "          callbacks=[es],\n",
    "          batch_size=32,\n",
    "          epochs=50,\n",
    "          validation_split=0.2,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24544/25000 [============================>.] - ETA: 0s\n",
      " Training Accuracy: 0.883\n",
      "Testing Accuracy:  0.859\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train)\n",
    "print(\"\\n Training Accuracy:\", score[1])\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
